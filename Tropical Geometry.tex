\documentclass[russian]{lecture-notes}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{amssymb}


\DeclareMathOperator{\trk}{trk}
\DeclareMathOperator{\Krk}{Krk}
\DeclareMathOperator{\Trop}{Trop}
\DeclareMathOperator{\Brk}{Brk}
\DeclareMathOperator{\trdeg}{trdeg}

\title{Гропическая геометрия глубоких нейронных сетей}
\author{Дмитрий Зайков, Олифер Максим}
\date{20.10.2019}


\begin{document}
	\begin{abstract}
		Впервые мы установили связь между нейронными сетями без обратной связи с ReLU активациями и тропической геометрией ~--- мы показываем, что семейство таких нейронных сетей эквивалентна семейству тропических рациональных карт. Среди прочего, мы вывели, что ReLU нейросеть без обратной связи с одним скрытым слоем может быть характеризована зонотопами, которые могут послужить блоками для строительства более глубоких сетей; мы связываем определение границ таких нейронных сетей с тропическими гиперповерхностями, главный объект изучения в тропической геометрии; и мы доказываем, что линейные области таких нейронных сетей соответствуют вершинам политопов, связанных с тропическими рациональными функциями. Вывод из нашей тропической формулировки такой, что более глубокая нейронная сеть экспоненциально лучше выражает, чем менее глубокая.
	\end{abstract}

	\section{Введение}
	
	Глубокие нейронные сети недавно получили много внимания за их огромный успех в ряде приложений из многих областей искуственного интеллекта, компьютерного зрения, распознавания речи и генерации естественного языка. (LeCun et al., 2015; Hinton et al., 2012; Krizhevsky et al., 2012; Bahdanau et al., 2014; Kalchbrenner \& Blunsom, 2013). Тем не менее, также известно, что наше теоретическое понимание их эффективности остается неполным.
	
	Было несколько попыток анализа глубоких нейронных сетей с разных перспектив. Особенно ранние работы показали, что глубокие архитектуры могут использовать параметры более эффективно и требуют экспоненциально меньше параметров, чтобы выражать определенные семейства функций, чем менее неглубокие архитектуры (Delalleau \& Bengio, 2011; Bengio \& Delaleau, 2011; Montufar et al., 2014; Eldan \& Shamir, 2016; Poole et al., 2016; Arora et al., 2018). Недавняя работа (Zhang et al., 2016) показала, что несколько успешных нейронных сетей обладают большой репрезентативностью и могут легко разбивать случайные данные. Однако они также хорошо обобщают данные, которые они не видели, во время тренировочного этапа, поэтому можно предположить, что такие сети могут иметь некоторую встроенную регуляризацию. Традиционные меры сложности, такие как размерность Вапника-Червоненкиса и Rademacher complexity, не могут объяснять данный феномен. Понимание данной встроенной регуляризации, порождающей обобщающую мощь глубоких нейронных сетей остается проблемой.
	
	Цель нашей работы - установить связи между нейронными сетями и тропической геометрией в надежде, что она прольет свет на работу глубоких нейронных сетей. Тропическая геометрия это новая область алгебраической геометрии, пережившей взрывной рост за последнюю декаду, но остающейся относительно беззвестной за пределами чистой математики. Мы сконцентрируемся на нейронных сетях без обратной связи с ReLU и покажем, что они являются аналогаим рациональных функций, т.е. отношением двух многомерных многочленов f, g для переменных $x_1,...,x_d$,
	
	\begin{equation*}
	\frac{f(x_1,...,x_d)}{g(x_1,...,x_d)},
	\end{equation*}
	
	в тропической геометрии. Для стандартных и тригонометрических полиномов известно, что рациональная аппроксимация --- это приближение функции отношением двух полиномов вместо одного полинома --- значительно улучшает качество аппроксимации без повышения степени. Это дает аналогию: нейронная сеть с ReLU это тропическое отношение двух тропических многочленов, т.е. тропическая рациональная функция. Точнее, если мы рассмотрим нейронную сеть как функцию $v : R^d \Rightarrow R^p, x=(x_1,...,x_d) \implies ((v_1(x)),...,v_p(x))$, где каждая v это тропическое пространство, т.е. каждая v это тропическая рациональная функция. Фактически, мы покажем, что
	
	
	\textit{семейство функций, представленных нейронной сетью без обратной связи с ReLU и целочисленными весами это в точности семейство тропических рациональных пространств.}
	
	Отсюда немедленно следует, что на данном семействе существует полуполе. Что более важно, это устанавливает мост между нейронными сетями и тропической геометрией, что позволяит нам рассмотреть нейронные сети как хорошо изученные тропические объекты. Это знание помогает нам связать ближе гриницы между линейными областями в нейронных сетях с тропическими гиперповерхностями и тем самым способствовать в определентю границ нейронной сети для проблемы классификации как тропических гиперповерхностей. Более того, количество линейных областей, что является мерой сложности нейронной сети (Montufar et al., 2014; Raghu et al., 2017; Arora
	et al., 2018), может быть ограничено количеством вершин политопа, связанного с тропическим представлением нейронной сети. Наконец, нейронная сеть с одним скрытым слоем может быть полностью характеризована зонотопом, который служит строительным блоком для более глубоких сетей.
	
	В разделах 2 и 3 мы введем необходимую нам базу тропической алгебры и тропической геометрии. Мы точно определим предположения в разделе 4 и установим связь между тропической геометрией и многослойной нейронной сетью в разделе 5. Мы проанализируем нейронные сети с помощью тропических методов в разделе 6, доказывая, что более глубокая нейросеть экспоненциально лучше выражает, чем менее глубокая --- хотя наша цель не столько показать результат анализа, сколько продемонстрировать, как тропическая геометрия может помочь получить полезные знания. Все доказательства отложены в раздел D дополнения.
	
	\section{Тропическая алгебра}
	
	Грубо говоря, тропическая алгебраическая геометрия - аналогия классической алгебраической геометрии над $\mathbb{C}$, полем комплексных чисел, но где $\mathbb{C}$ заменяется на полуполе, называемое тропическим полукольцом, которое будет определено далее. Мы предоставим краткий обзор тропической алгебры и введем некоторые связанные условные обозначения. См. (Itenberg et al., 2009; Maclagan \& Sturmfels,
	2015) для более глубокого изучения.
	
	Самый фундаментальный компонент тропической геометрии - \textit{тропическое полукольцо} $\mathbb{T}$ := $ (\mathbb{R} \cup \{- \infty \}, \oplus, \odot)$. Два оператора $\bigoplus$ и $\bigodot$, называемые \textit{тропическое сложение} и \textit{тропическое умножение} соответственно, определяются следующим образом:
	
	\begin{Definition}
		Для x, y $\in $ $ \mathbb{R}$ их тропическая сумма это x $\bigoplus$ y := max\{x, y\}; их тропическое произведение это x $\odot$ y := x + y; тропическое частное x $\oslash$ y := x - y.
	\end{Definition}
	
	\section{Тропическая геометрия нейронных сетей}
	
	В разделе 5 нейронные сети определяются с помощью тропической алгебры, что позволяет нам изучать их с помощью тропической алгебраической геометрии. Мы покажем, что граница принятий решений нейронной сети ~--- это подмножество тропической гиперповерхности, соответствующего тропического полинома(Раздел 6.1). Мы увидим, что в некотором смысле, зонотопы образуют геомтрические строительные блоки для нейронных сетей (Раздел 6.2). Затем мы докажем, что геометрия функции, представленной нейронной сетью, становится значиттельно более сложной с увеличением ее количества слоёв.
	\subsection{Границы решений нейронной сети}
	
	Мы будем использовать тропическую геометрию и идеи из Раздела 5 для изучения границ решений нейронных сетей, фокусируясь на случае классификации двух категорий для ясности. Как объяснено в Разделе 4, нейронная сеть $\nu : \mathbf{R}^d \rightarrow \mathbf{R}^p$ вместе с выбором функции оценки $s: \mathbf{R}^p \rightarrow \mathbf{R}$ дают нам классификатор. Если выходное значение $s(\nu(x))$ превышает некоторый порог принятия решений $c$, то нейронная сеть предсказывает, что $x$ относится к одной категории (например, $x$ ~--- изображение кота), а в противном случае $x$ относится к другой категории (например, $x$ ~--- изображение собаки). Таким образом входной пространство разделено на два непересекающихся подмножества \textit{границей принятия решений $B := \{x \in \mathbf{R}^d : \nu(x) = s^{-1}(c)\} $}. Связанные области со значением выше порога и связные области со значением ниже порога будем называть \textit{положительными} и \textit{отрицательными областями} соответственно.
	
	Предоставим оценки на количество положительных и отрицательных областей и покажем, что существует тропический многочлен, чья тропическая гиперповерхность содержит границу решений.
	\begin{Proposition}
		(Тропическая геометрия границы решений). Пусть $\nu : \mathbf{R}^d \rightarrow \mathbf{R}$  ~--- $L$-слойная нейронная сеть, удовлетворяющая предположению $(a)-(c)$ с $t^{(L)} = -\infty$. Пусть функция счета $s : \mathbf{R} \rightarrow \mathbf{R}$  является иньъективной с порогом принятия решений $c$ в его диапазоне. Если $\nu = f \oslash g$, где $f$ и $g$ ~--- тропические многочлены, тогда 
		\begin{enumerate}
			\item Его граница решений $B = \{x \in \mathbf{R}^d:\nu(x) = s^{-1}(c)\}$ делит $\mathbf{R}^d$ на не более чем $N(f)$ связных положительных областей и не более, чем $N(g)$ связных отрицательных областей;
			\item Его раница решений содержится в тропической гиперповерхности тропического многочлена $s^{-1}\odot g(x)\oplus f(x) = \max\{f(x),g(x)+s^{-1}(c)\}$, то есть 
				\[B 
				\subset T(s^{-1}(c)\odot g \oplus f)
				\]  
		\end{enumerate}
	
		Функция $s^{-1}(c) \odot g \oplus f$ не обязательно линейна на каждой положительной или отрицательной области и поэтому ее тропическая гиперповерхность $T(s^{-1}(c)\odot g \oplus f)$ может дальше делить положительные или отрицательные области, полученные из $B$ на несколько линейных областей. В общем случае $\subset$ нельзя заменить на $=$.
	\end{Proposition}

	\subsection{Зонотопы, как геометрические строительные блоки нейронной сети}
	
	Из раздела 3, мы знаем, что число областей тропической гиперповерхности $T(f)$ делит пространство на равное число вершин в двойственном разбиении многоугольника Ньютона, связанного с тропическим многочленом $f$. Это позволяет нам ограничить количество линейных областей нейронной сети, ограничивая число вершин в двойственном разбиении многоугольника Ньютона. 
	
	Мы начнём изучение того, как геометрия меняется от одного слоя к следующему в нейронной сети, более точнее:
	
	\begin{Question}
		Как тропические гиперповерхности тропических многочленов в $(l + 1)$-ом слое нейронной сети связаны с ими в $l$-ом слое?
		содержимое...
	\end{Question}
	
	Рекуррентное соотношение (2) описывает, как тропические многочлены, встречающиеся в $(l + 1)$-ом слое получаются из многочленов в $l$-ом слое, а именно, через три операции: тропическая сумма, тропическую степень и тропическое умножение. Напомним, что тропическая гиперповерхность тропического многочлена ~--- двойственно разбиение многогранника Ньютона тропического многочлена, который задается проекцией верхних граней на многогранники, определяемые формулой (1). Отсюда вопрос сводится к тому, как эти три операции преобразуют многогранники, а это рассматривается в утверждениях 3.1 и 3.2. Мы следуем обозначениям из Утверждения 5.1 для следующего результата.
	
	\begin{Lemma}
		Пусть $f_i^{(l)},g_i^{(l)},h_i^{(l)}$ тропические многочлены, созданные $i$-ым узлом в $l$-ом слое нейронной сети, то есть они определяются как (2). Тогда $P(f_i^{(l)}, P(g_i^{(l)},P(h_i^{(l)}$, являющиеся подмножествами $\mathbf{R}^{d+1}$, задаются следующим образом:
		\begin{enumerate}
			\item $P(g_i^{(1) \text{ и } P(h_i^{(1)}}$ являются точками.
			\item $P(f_i^{(1)}$ ~--- отрезок.
			\item $P(g_i^{(1) \text{ и } P(h_i^{(1)}}$ ~--- зонотопы.
			\item Для $l \geq 1$,
			\[
				P(h_i^{(l)}) = Conv[P(g_i^{(l)}\odot t_i^{(l)}) \cup P(h_i^{(l)})]
			\]
			
			Если $t_i^{(l)} \in \mathbf{R}$, и $P(f_i^{(l)}) = P(h_i^{(l)})$, если $t_i^{(l)} = -\infty$
			\item Для $l \geq  1, P(g_i^{(l+1)})\text{ и } P(h_i^{(l+1)}) $ взвешены суммы Минковского, 
			\[
				P(g_i^{(l+1)}) = \sum\limits_{j=1}^{n_l} a_{ij}^-P(f_i^{(l)}) + \sum\limits_{j=1}^{n_l} a_{ij}^+P(g_i^{(l)}),
			\]
			\[
			P(h_i^{(l+1)}) = \sum\limits_{j=1}^{n_l} a_{ij}^+P(f_i^{(l)}) + \sum\limits_{j=1}^{n_l} a_{ij}^-P(g_i^{(l)})
			\]
			\[
				+\{b_ie\},
			\]
			
			Где $a_{ij}, b_i$ записаны в матрице весов $A^(l+1) \in \mathbf{Z}^{n_{l+1}\times n_l}$ и вектор смещения $b^(l+1) \in \mathbf{R}^{n_l+1} \text{ и } e:= (0, \dots,0,1)\in \mathbf{R}^{d+1}$.			
		\end{enumerate}
		\end{Lemma}
		Завершение леммы 6.2 состоит в том, что зонотопы являются строительными блоками в тропической геометрии нейронных сетей. Зонотопы широко изучены в выпуклой геометрии и, среди прочего, они тесно связаны с расположением гиперплоскостей. Лемма 6.2 связывает нейронные сети с этим обширным объёмом работы, но полный смысл этого еще предстоит изучить. В разделе С.2, кроме того, мы покажем, как можно построить эти многогранники для двуслойных нейронных сетей.
		
		\subsection{Геометрическая сложность глубоких нейронных сетей}
		
		Мы обращаемся к инструментам из раздела 3 для изучения сложности нейронной сети, показывая, что глубокая сеть более выразительна, чем неглубокая. Наша мера сложности является геометрической: мы будему следовать (Montufar et al., 2014;
		Raghu et al., 2017) и использовать количество линейных областей кусочно-линейной функции $\nu : \mathbf{R}^d \rightarrow \mathbf{R}^p$ для измерения сложности $\nu$.
		
		\begin{Theorem}
			Пусть $\nu : \mathbf{R}^d \rightarrow \mathbf{R}$ является $L$-слоем вещественной нейронной сетью с прямой связью, удовлетворяющей (a)-(c). Пусть $t^{(L)} = -\infty$ и $n_l \geq d$ для всех $l = 1,\dots,L-1$. Тогда $\nu = \nu^{(L)}$ имеет максимум
			\[
				\prod\limits_{l=1}^{L-1}\sum\limits_{i = 0}^{d} \begin{pmatrix}
				n_l\\
				i
				\end{pmatrix}
			\]
			линейных областей. В частности, если $d\leq n_1,\dots ,n_{L-1} \leq n$, то число линейных областей $\nu$ ограничено $O(n^{d(L-1)})$.
		\end{Theorem}
		
		\begin{Proof}
			Если $L = 2$, то это следует непосредственно из Леммы 6.2 и Следствия 3.4. Случай, когда $L \geq 3$ находится в разделе 7, в дополнении.
		\end{Proof}
	
	Как отмечалось в (Raghu et al., 2017), эта верхняя граница близко соответствует нижней границе $\Omega ((\frac{n}{d}^{(l-1)d})  n^d)$ в (Montufar et al., 2014, Corollary 5), когда $n_1 = \cdots = n_{L-1} = n \geq d$. отсюда мы предполагаем, что число линейных областей нейронной сети растёт полиномиально с шириной $n$ и экспоненциально с количеством слоёв $L$.
	
	\subsection{Заключение}
	
	Мы утверждаем, что прямые нейронные сети с выпрямленными узлами не что иное, как тропические рациональные карты. Чтобы понять их, нам зачастую нужно понимать соответствующую тропическую геометрию.
	
	В этой статье мы сделали первый шаг, чтобы предоставить подтверждение концепции: вопросы, касающиеся границ решений, линейных областей, как глубина влияет на выразительность и т.д. можно перевести на вопросы, касающиеся тропических гиперповерхностей, разбиений многоугольника Ньютона, многогранников, построенных из зонотопов и др.
	
	Как новая ветвь алгебраической геометрии, новшество тропической геометрии происходит из алгебры и геометрии и их взаимодействует друг с другом. Она связана множеством других областей математики. Среди прочих вещей, существует тропический аналог линейной алгебры и тропический аналог выпуклой геометрии. Мы затронули лишь небольшую часть этого богатого предмета. Мы надеемся, что дальнейшее исследование под тропическим углом поможет разгадать другие загадки глубоких нейронных сетей.
	
\end{document}